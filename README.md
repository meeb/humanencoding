# humanencoding

Reference implementation of encoding bytes to human readable words.

# Why

There are multiple reasons why short byte strings may be required to be
converted to human readable strings. Example use cases are hashes and other
cryptographic primitives, checksums etc.

# Another one?

There are multiple implementations of human encoded binary information,
including examples including [RFC 1751][1], however they have have drawbacks such
as fixed input sizes, very large outputs or limited memorability of the output
due to the small size of the dictionary used.

# Implementation

Input bytes should be read in groups of two. If the input is of an odd length
a zero (\0) should be appended to make the input an even length.

The input should then be iterated two bytes at a time. Each two bytes should be
treated as a short integer consisting of two bytes. The resulting number for
each group of two bytes will be an integer between 0 and 65535.

The resulting number is used as an index in a lookup table of 65536 English
words.

To convert words back into binary simply reverse the procedure. Look up each
word in the dictionary and record the index position. Convert the short
integer back into two bytes. Append all the bytes together.

This repository contains a reference implementation in several languages.

# Drawbacks

This implementation is simple to follow, trivial to implement and produces
the most readable strings of any implementation, however the critial issue
is that the dictionary of 65535 words must remain static and be shipped with
all implementations. Luckily, 65535 words are not very large for all but the
most minimal environments to handle so this should not be a drawback for
developers.

# Word list

The most critical part of the implementation is the static word list. This was
generated by taking the `words` file from the `wamerican` package on Debian
linux which contains 99171 words and processed the file in the following order:

* lowercase all words
* removing all words that are not purely lowercase a-z
* removing all brand names
* removing all abusive words or words that contain abusive words
* removing all words under 3 letters in length
* removing all words that are over 8 letters in length
* ordering the remaining words by number of syllables and truncate any words
  over position 65536
* re-order the remaining 65536 words alphabetically

There is an implementation if this generator in the `wordlists` directory.

# Contribution

Please submit pull requests for missing brand names or abuse terms that should
be filtered or if you implement this encoding in any missing language.



[1]: https://tools.ietf.org/html/rfc1751
